{"kind":"Notebook","sha256":"f09e929f277bc63c40594b6b43947744cde046431767f8bc06f9dd310e12c0de","slug":"optional-programming-dmp-generation","location":"/exercise1/Optional_Programming_DMP_generation.ipynb","dependencies":[],"frontmatter":{"title":"Optional: Programming DMP Generation","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"Robert Haase","given":"Robert","family":"Haase"},"name":"Robert Haase","orcid":"0000-0001-5949-2327","github":"haesleinhuepf","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Ronny Gey","given":"Ronny","family":"Gey"},"name":"Ronny Gey","orcid":"0000-0003-1028-1670","affiliations":["ufz"],"github":"geyslein","id":"contributors-myst-generated-uid-1"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/ScaDS/ai_training_ufz_2025","keywords":["AI","OER"],"copyright":"Copyright: Ronny Gey, UFZ Leipzig, Robert Haase, ScaDS.AI Leipzig, licensed <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">CC-BY 4.0</a> unless mentioned otherwise. Contributions and feedback are welcome.","affiliations":[{"id":"ufz","name":"Helmholtz Center for Environmental Research - UFZ","ror":"000h6jb29"}],"exports":[{"format":"ipynb","filename":"Optional_Programming_DMP_generation.ipynb","url":"/Optional_Programming-35013fa921f58a5ebf1e35d47a10cb55.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"In this notebook I will use the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"fj9IzxB6x7"},{"type":"link","url":"https://sdlaml.pages.jsc.fz-juelich.de/ai/guides/blablador_api_access/#step-1-register-on-gitlab","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Blablador API","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"eJrdnIP9x9"}],"urlSource":"https://sdlaml.pages.jsc.fz-juelich.de/ai/guides/blablador_api_access/#step-1-register-on-gitlab","key":"dRXNBo0Ag2"},{"type":"text","value":" to turn a fictive project description and a skeleton for a Data Management Plan (DMP) into a project-specific DMP. If you want to rerun this notebook, you need a Blablador API key, and store it as ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ameTLg1qsh"},{"type":"inlineCode","value":"BLABLADOR_API_KEY","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"MRpzOMUSTG"},{"type":"text","value":" in your environment variables. Also make sure to execute this notebook in an environment where the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"XMj590nlHk"},{"type":"link","url":"https://pypi.org/project/openai/","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"openai python library","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"CjYTF9h55v"}],"urlSource":"https://pypi.org/project/openai/","key":"IfKJVFesaP"},{"type":"text","value":" is installed, e.g. using ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"YtXpldKDcQ"},{"type":"inlineCode","value":"pip install openai","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"FIHSsLnSBf"},{"type":"text","value":".","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"q3q9jU3xRB"}],"key":"EUZcFXm7Ib"}],"key":"CFSHG2aQIJ"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"import openai\nfrom IPython.display import display, Markdown","key":"ryzzjgpkgZ"},{"type":"output","id":"DnNxHr6vEAGcPcgNlyMwn","data":[],"key":"q1HKGl9NkL"}],"key":"ETjKWUTaXw"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We define some helper-function to send a prompt to blablador and retrieve the result. (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WmqxuPhDJW"},{"type":"link","url":"https://scads.github.io/generative-ai-notebooks/15_endpoint_apis/03_blablador_endpoint.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"source","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iQNJvlCA8p"}],"urlSource":"https://scads.github.io/generative-ai-notebooks/15_endpoint_apis/03_blablador_endpoint.html","key":"FsdXgx9TL2"},{"type":"text","value":")","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MjCcSpsWlM"}],"key":"emKs8aKAmC"}],"key":"lzGTkY4YVW"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"def prompt(message:str, model=\"1 - Llama3 405 on WestAI with 4b quantization\"):\n    \"\"\"A prompt helper function that sends a message to Blablador (FZ Jülich)\n    and returns only the text response.\n    \"\"\"\n    import os\n    import openai\n    \n    # setup connection to the LLM\n    client = openai.OpenAI()\n    client.base_url = \"https://helmholtz-blablador.fz-juelich.de:8000/v1\"\n    client.api_key = os.environ.get('BLABLADOR_API_KEY')\n    response = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": message}]\n    )\n    \n    # extract answer\n    return response.choices[0].message.content","key":"uvyjHOliHv"},{"type":"output","id":"ucH0_VI8SEDisFvnWMhxz","data":[],"key":"GPtpnUknNJ"}],"key":"sM2tR4MiAD"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Asking chatGPT about DMPs","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YDR6KH8A2P"}],"identifier":"asking-chatgpt-about-dmps","label":"Asking chatGPT about DMPs","html_id":"asking-chatgpt-about-dmps","implicit":true,"key":"fHnoCsW3W7"}],"key":"fGuzuRYcNE"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"result = prompt(\"\"\"\nGive me a short list of typical sections of a Data Management Plan. \nWrite bullet points in markdown format and no detailed explanation.\n\"\"\")\n\ndisplay(Markdown(result))","key":"rAElobK8Nr"},{"type":"output","id":"mHEEJVf9XSEDcJCUMt-UJ","data":[{"output_type":"display_data","metadata":{},"data":{"text/markdown":{"content":"* Data Types and Formats\n* Data Collection and Storage\n* Data Sharing and Access\n* Data Quality and Validation\n* Data Security and Backup\n* Data Archiving and Preservation\n* Data Sharing and Reuse\n* Roles and Responsibilities","content_type":"text/markdown"},"text/plain":{"content":"<IPython.core.display.Markdown object>","content_type":"text/plain"}}}],"key":"nZ87XI3bxi"}],"key":"m5bXZyMj72"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"result = prompt(\"\"\"\nWhat is commonly described in a section about \"Backup and Archiving\" in a \nData Management Plan? Answer in 3 sentences.\n\"\"\")\n\ndisplay(Markdown(result))","key":"mBDYLhnpuK"},{"type":"output","id":"hZcjy5CP6I3Y7O2gqrxD7","data":[{"output_type":"display_data","metadata":{},"data":{"text/markdown":{"content":"In a Data Management Plan, the \"Backup and Archiving\" section typically describes the procedures for creating and managing backup copies of research data to ensure its availability and integrity in case of data loss or corruption. This section may outline the frequency and method of backups, the type of storage media used, and the location of backup storage. Additionally, it may discuss long-term archiving plans, including the format and storage of data for preservation and potential reuse.","content_type":"text/markdown"},"text/plain":{"content":"<IPython.core.display.Markdown object>","content_type":"text/plain"}}}],"key":"DwHUlKYR3l"}],"key":"FXASR87NJG"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Our project description","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vlYyZYH0o0"}],"identifier":"our-project-description","label":"Our project description","html_id":"our-project-description","implicit":true,"key":"vhdGGyqkb4"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"In the following cell you find a description of a fictive project. It contains all aspects of such a project that came to my mind when I though of the aspects chatGPT mentioned above. It is structured chronologously, listing things that happen early in the project first, and transitioning towards publication of a manuscript, code and data.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"VW9s1akBKI"}],"key":"oaagh3KVAw"}],"key":"AvQ2FihAUP"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"project_description = \"\"\"\nIn our project we investigate the underlying physical principles for Gastrulation \nin Tribolium castaneum embryo development. Therefore, we use light-sheet microscopes\nto acquire 3D timelapse imaging data. We store this data in the NGFF file format. \nAfter acquistion, two scientists, typically a PhD student and a post-doc or \ngroup leader look into the data together and decide if the dataset will be analyzed \nin detail. In case yes, we upload the data to an Omero-Server, a research data \nmanagement solution specifically developed for microscopy imaging data. Data on \nthis server is automatically backed-up by the compute center of our university. We then login \nto the Jupyter Lab server of the institute where we analyze the data. Analysis results\nare also stored in the Omero-Server next to the imaging data results belong to. The\nPython analysis code we write is stored in the institutional git-server. Also this \nserver is backed up by the compute center. When the project advances, we start writing\na manuscipt using overleaf, an online service for collaborative manuscipt editing \nbased on latex files. After every writing session, we save back the changed manuscript \nto the institutional git server. As soon as the manuscript is finished and \nsubmitted to the bioRxiv, a preprint server in the life-sciences, we also publish the \nproject-related code by marking the project on the git-server as public. We also\ntag the code with a release version. At the same time we publish the imaging data \nby submitting a copy of the dataset from the Omero-Server to zenodo.org, a \ncommunity-driven repository for research data funded by the European Union. Another \ncopy of the data, the code and the manuscript is stored on the institutional archive \nserver. This server, maintained by the compute center, garantees to archive data for \n15 years. Documents and data we published is licensed under CC-BY 4.0 license. The code \nwe publish is licensed BSD3. The entire project and all steps of the data life-cycle \nare documented in an institutional labnotebook where every user has to pay 10 Euro \nper month. Four people will work on the project. The compute center estimates the \ncosts for storage and maintenance of the infrastructure to 20k Euro and half a \nposition of an IT specialist. The project duration is four years.\n\"\"\"","key":"xJEtpVbljx"},{"type":"output","id":"2yXLu_v3IV-NsTQfdAVS3","data":[],"key":"baWw7Ebif9"}],"key":"IZYET5asIJ"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can then use this project description as part of a prompt to chatGPT to turn this unstructured text into a DMP.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TmSX55WXCg"}],"key":"IY1S9Tlpbd"}],"key":"EKcCJxyDpn"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"result = prompt(f\"\"\"\nYou are a professional grant proposal writer. In the following comes a description of \na common project in our \"Tribolium Development\" Research Group at the University. \nYour task is to reformulate this project description into a Data Management Plan.\n\n{project_description}\n\"\"\")\n\ndisplay(Markdown(result))","key":"hKtz2AkECE"},{"type":"output","id":"c1Z10uWrKDMuFQxBDlLsy","data":[{"output_type":"display_data","metadata":{},"data":{"text/markdown":{"content":"**Data Management Plan for \"Tribolium Development\" Research Group**\n\n**Project Overview**\n\nOur research group aims to investigate the underlying physical principles for Gastrulation in Tribolium castaneum embryo development. This project will generate large amounts of 3D timelapse imaging data, which will be analyzed and published in accordance with the principles of open science.\n\n**Data Generation and Storage**\n\n* 3D timelapse imaging data will be acquired using light-sheet microscopes and stored in the NGFF file format.\n* All imaging data will be uploaded to an Omero-Server, a research data management solution specifically developed for microscopy imaging data, which is automatically backed up by the compute center of our university.\n* The Omero-Server will store both raw and analyzed data, ensuring that all data is properly versioned and linked to relevant metadata.\n\n**Data Analysis and Code Management**\n\n* Data analysis will be performed using Jupyter Lab server, which is connected to the Omero-Server.\n* Analysis code will be written in Python and stored in the institutional git-server, which is backed up by the compute center.\n* All code will be version-controlled, and changes will be tracked through the git-server.\n\n**Collaboration and Manuscript Writing**\n\n* Manuscripts will be written collaboratively using Overleaf, an online service for collaborative manuscript editing based on LaTeX files.\n* Manuscript versions will be saved regularly to the institutional git-server.\n\n**Data and Code Publication**\n\n* Upon manuscript submission to bioRxiv, a preprint server in the life sciences, the project-related code will be made public by marking the project on the git-server as public and tagging the code with a release version.\n* Imaging data will be published by submitting a copy of the dataset from the Omero-Server to Zenodo.org, a community-driven repository for research data funded by the European Union.\n\n**Long-term Preservation and Archiving**\n\n* A copy of the data, code, and manuscript will be stored on the institutional archive server, which is maintained by the compute center and guarantees data archiving for 15 years.\n\n**Licensing and Access**\n\n* All published data and documents will be licensed under the CC-BY 4.0 license.\n* Published code will be licensed under the BSD3 license.\n\n**Documentation and Project Management**\n\n* The entire project and all steps of the data life cycle will be documented in an institutional lab notebook, accessible to all project members.\n* Four people will work on the project, and the compute center estimates the costs for storage and maintenance of the infrastructure to be 20k Euro and half a position of an IT specialist.\n\n**Project Timeline and Funding**\n\n* The project duration is four years.\n* Funding for the project has been allocated to cover the costs of storage, maintenance, and personnel.\n\nBy following this Data Management Plan, our research group aims to ensure that all data and code generated during this project are properly stored, analyzed, and published in accordance with the principles of open science, and that all data and materials are preserved for long-term access and reuse.","content_type":"text/markdown"},"text/plain":{"content":"<IPython.core.display.Markdown object>","content_type":"text/plain"}}}],"key":"OfBOEVyvzd"}],"key":"TGnRwfJy9K"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Combining information and structure","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XjndXZow8o"}],"identifier":"combining-information-and-structure","label":"Combining information and structure","html_id":"combining-information-and-structure","implicit":true,"key":"WzbcRELBqM"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We next modify the prompt to also add information about the structure we need. This structure may be different from funding agency to funding agency and thus, this step is crucial in customizing the DMP accoring to given formal requirements.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"p865ZIicHB"}],"key":"A0zoDd1Dae"}],"key":"g8rJxCY9Go"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"result = prompt(f\"\"\"\nYou are a professional grant proposal writer. In the following comes a description of \na common project in our \"Tribolium Development\" Research Group at the University. \nYour task is to reformulate this project description into a Data Management Plan.\n\n{project_description}\n\nThe required structure for the data management plan, we need to write is like this:\n\n# Data Management Plan\n## Data description\n## Documentation and data quality\n## Storage and technical archiving the project\n## Legal obligations and conditions \n## Data exchange and long-term data accessibility\n## Responsibilities and resources\n\nUse Markdown for headlines and text style.\n\"\"\")\n\ndisplay(Markdown(result))","key":"yftossHuY6"},{"type":"output","id":"KknvGPEBzjBYzv8eeq0dl","data":[{"output_type":"display_data","metadata":{},"data":{"text/markdown":{"content":"# Data Management Plan\n\n## Data description\n\nIn this project, we will generate 3D timelapse imaging data of Tribolium castaneum embryo development using light-sheet microscopes. The data will be stored in the NGFF file format. Additionally, we will produce analysis results, Python code for data analysis, and a manuscript.\n\n## Documentation and data quality\n\n* All data and analysis steps will be documented in an institutional lab notebook, accessible to all project members at a cost of €10 per month per user.\n* Data quality will be ensured through collaborative review by at least two scientists (PhD student and post-doc or group leader) before deciding on further analysis.\n* Analysis code will be stored in an institutional Git-server, with regular backups by the compute center.\n\n## Storage and technical archiving the project\n\n* Imaging data will be stored on an Omero-Server, a research data management solution specifically developed for microscopy imaging data, with automatic backups by the compute center.\n* Analysis results will be stored alongside the imaging data on the Omero-Server.\n* Python analysis code will be stored in the institutional Git-server, with regular backups by the compute center.\n* Manuscript drafts will be stored on the institutional Git-server, with regular backups by the compute center.\n* A copy of the dataset, code, and manuscript will be archived on the institutional archive server, maintained by the compute center, which guarantees data archiving for 15 years.\n\n## Legal obligations and conditions\n\n* All published data, code, and manuscripts will be licensed under CC-BY 4.0 (data and manuscripts) or BSD3 (code).\n* The project will comply with the European Union's data protection regulations.\n\n## Data exchange and long-term data accessibility\n\n* Imaging data will be published on zenodo.org, a community-driven repository for research data, upon manuscript submission to bioRxiv.\n* Analysis code will be made publicly available on the institutional Git-server, with a release version tag, upon manuscript submission.\n* The institutional archive server will ensure long-term data accessibility for at least 15 years.\n\n## Responsibilities and resources\n\n* Four project members will be responsible for data management and analysis.\n* The compute center will provide storage and maintenance of the infrastructure at an estimated cost of €20,000 and half a position of an IT specialist.\n* The project duration is four years.","content_type":"text/markdown"},"text/plain":{"content":"<IPython.core.display.Markdown object>","content_type":"text/plain"}}}],"key":"drfL2ak4Lc"}],"key":"NqH68e8qU4"}],"key":"H0dBk0qmRx"},"references":{"cite":{"order":[],"data":{}}}}